{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported dataset\n",
    "Facial Emotion Recognition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'fer2013.csv'\n",
    "image_size=(48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fer2013.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fer2013():\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    pixels = data['pixels'].tolist()\n",
    "    width, height = 48, 48\n",
    "    faces = []\n",
    "    for pixel_sequence in pixels:\n",
    "        face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "        face = np.asarray(face).reshape(width, height)\n",
    "        face = cv2.resize(face.astype('uint8'),image_size)\n",
    "        faces.append(face.astype('float32'))\n",
    "    faces = np.asarray(faces)\n",
    "    faces = np.expand_dims(faces, -1)\n",
    "    emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "    return faces, emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed the data \n",
    "Converted the dataset in the range of 0 to 1 by diving each pixel by 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model CNN\n",
    "Imported all the required package\n",
    "Used 'relu' as an input for activation function\n",
    "Then used average pooling for dimension reduction.\n",
    "To increase the accuracy and decrease the time, we used Dropout method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model implementation \n",
    "Built various CNN model by changing the parameters.\n",
    "Dropped out 20 percent of total connections between the layers randomly.\n",
    "Used softmax as last layer for making pedictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rosha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\rosha\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_array (Conv2D)         (None, 48, 48, 16)        800       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 16)        12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 7)           16135     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 642,935\n",
      "Trainable params: 641,463\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def simple_CNN(input_shape, num_classes):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same',\n",
    "                            name='image_array', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax',name='predictions'))\n",
    "    return model\n",
    "\n",
    "def simpler_CNN(input_shape, num_classes):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(5, 5), padding='same',\n",
    "                            name='image_array', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(5, 5),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax',name='predictions'))\n",
    "    return model\n",
    "\n",
    "def tiny_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(5, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(5, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(8, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(8, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(8, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n",
    "\n",
    "def big_XCEPTION(input_shape, num_classes):\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n",
    "    x = BatchNormalization(name='block1_conv1_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv1_act')(x)\n",
    "    x = Conv2D(64, (3, 3), use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block1_conv2_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block2_sepconv2_act')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = Activation('relu', name='block3_sepconv1_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block3_sepconv2_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (64, 64, 1)\n",
    "    num_classes = 7\n",
    "    #model = tiny_XCEPTION(input_shape, num_classes)\n",
    "    #model.summary()\n",
    "    #model = mini_XCEPTION(input_shape, num_classes)\n",
    "    #model.summary()\n",
    "    #model = big_XCEPTION(input_shape, num_classes)\n",
    "    #model.summary()\n",
    "    model = simple_CNN((48, 48, 1), num_classes)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from load_and_process import load_fer2013\n",
    "#from load_and_process import preprocess_input\n",
    "#from models.cnn import mini_XCEPTION\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 35\n",
    "input_shape = (48, 48, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 46, 46, 8)    72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 46, 46, 8)    32          conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 46, 46, 8)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 44, 44, 8)    576         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 44, 44, 8)    32          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 44, 44, 8)    0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_1 (SeparableCo (None, 44, 44, 16)   200         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 44, 44, 16)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_2 (SeparableCo (None, 44, 44, 16)   400         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 44, 44, 16)   64          separable_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 22, 22, 16)   128         activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 22, 22, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 22, 22, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 22, 22, 16)   0           max_pooling2d_1[0][0]            \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_3 (SeparableCo (None, 22, 22, 32)   656         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 22, 22, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_4 (SeparableCo (None, 22, 22, 32)   1312        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 22, 22, 32)   128         separable_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 11, 11, 32)   512         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 32)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 11, 11, 32)   128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 11, 11, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_5 (SeparableCo (None, 11, 11, 64)   2336        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 11, 11, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_6 (SeparableCo (None, 11, 11, 64)   4672        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 11, 11, 64)   256         separable_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 6, 6, 64)     2048        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 64)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 6, 6, 64)     256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 6, 6, 64)     0           max_pooling2d_3[0][0]            \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_7 (SeparableCo (None, 6, 6, 128)    8768        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 6, 6, 128)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_8 (SeparableCo (None, 6, 6, 128)    17536       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 6, 6, 128)    512         separable_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 3, 3, 128)    8192        add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 3, 3, 128)    512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 3, 3, 128)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 3, 3, 7)      8071        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 7)            0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rosha\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[[ 70.],\n",
       "          [ 80.],\n",
       "          [ 82.],\n",
       "          ...,\n",
       "          [ 52.],\n",
       "          [ 43.],\n",
       "          [ 41.]],\n",
       " \n",
       "         [[ 65.],\n",
       "          [ 61.],\n",
       "          [ 58.],\n",
       "          ...,\n",
       "          [ 56.],\n",
       "          [ 52.],\n",
       "          [ 44.]],\n",
       " \n",
       "         [[ 50.],\n",
       "          [ 43.],\n",
       "          [ 54.],\n",
       "          ...,\n",
       "          [ 49.],\n",
       "          [ 56.],\n",
       "          [ 47.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 91.],\n",
       "          [ 65.],\n",
       "          [ 42.],\n",
       "          ...,\n",
       "          [ 72.],\n",
       "          [ 56.],\n",
       "          [ 43.]],\n",
       " \n",
       "         [[ 77.],\n",
       "          [ 82.],\n",
       "          [ 79.],\n",
       "          ...,\n",
       "          [105.],\n",
       "          [ 70.],\n",
       "          [ 46.]],\n",
       " \n",
       "         [[ 77.],\n",
       "          [ 72.],\n",
       "          [ 84.],\n",
       "          ...,\n",
       "          [106.],\n",
       "          [109.],\n",
       "          [ 82.]]],\n",
       " \n",
       " \n",
       "        [[[151.],\n",
       "          [150.],\n",
       "          [147.],\n",
       "          ...,\n",
       "          [129.],\n",
       "          [140.],\n",
       "          [120.]],\n",
       " \n",
       "         [[151.],\n",
       "          [149.],\n",
       "          [149.],\n",
       "          ...,\n",
       "          [122.],\n",
       "          [141.],\n",
       "          [137.]],\n",
       " \n",
       "         [[151.],\n",
       "          [151.],\n",
       "          [156.],\n",
       "          ...,\n",
       "          [109.],\n",
       "          [123.],\n",
       "          [146.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[188.],\n",
       "          [188.],\n",
       "          [121.],\n",
       "          ...,\n",
       "          [185.],\n",
       "          [185.],\n",
       "          [186.]],\n",
       " \n",
       "         [[188.],\n",
       "          [187.],\n",
       "          [196.],\n",
       "          ...,\n",
       "          [186.],\n",
       "          [182.],\n",
       "          [187.]],\n",
       " \n",
       "         [[186.],\n",
       "          [184.],\n",
       "          [185.],\n",
       "          ...,\n",
       "          [193.],\n",
       "          [183.],\n",
       "          [184.]]],\n",
       " \n",
       " \n",
       "        [[[231.],\n",
       "          [212.],\n",
       "          [156.],\n",
       "          ...,\n",
       "          [ 44.],\n",
       "          [ 27.],\n",
       "          [ 16.]],\n",
       " \n",
       "         [[229.],\n",
       "          [175.],\n",
       "          [148.],\n",
       "          ...,\n",
       "          [ 27.],\n",
       "          [ 35.],\n",
       "          [ 27.]],\n",
       " \n",
       "         [[214.],\n",
       "          [156.],\n",
       "          [157.],\n",
       "          ...,\n",
       "          [ 28.],\n",
       "          [ 22.],\n",
       "          [ 28.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[241.],\n",
       "          [245.],\n",
       "          [250.],\n",
       "          ...,\n",
       "          [ 57.],\n",
       "          [101.],\n",
       "          [146.]],\n",
       " \n",
       "         [[246.],\n",
       "          [250.],\n",
       "          [252.],\n",
       "          ...,\n",
       "          [ 78.],\n",
       "          [105.],\n",
       "          [162.]],\n",
       " \n",
       "         [[250.],\n",
       "          [251.],\n",
       "          [250.],\n",
       "          ...,\n",
       "          [ 88.],\n",
       "          [110.],\n",
       "          [152.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[ 17.],\n",
       "          [ 17.],\n",
       "          [ 16.],\n",
       "          ...,\n",
       "          [ 83.],\n",
       "          [114.],\n",
       "          [245.]],\n",
       " \n",
       "         [[ 18.],\n",
       "          [ 17.],\n",
       "          [ 16.],\n",
       "          ...,\n",
       "          [104.],\n",
       "          [136.],\n",
       "          [253.]],\n",
       " \n",
       "         [[ 19.],\n",
       "          [ 16.],\n",
       "          [ 17.],\n",
       "          ...,\n",
       "          [128.],\n",
       "          [152.],\n",
       "          [255.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[  4.],\n",
       "          [ 21.],\n",
       "          [ 46.],\n",
       "          ...,\n",
       "          [186.],\n",
       "          [180.],\n",
       "          [187.]],\n",
       " \n",
       "         [[  5.],\n",
       "          [ 17.],\n",
       "          [ 41.],\n",
       "          ...,\n",
       "          [177.],\n",
       "          [172.],\n",
       "          [176.]],\n",
       " \n",
       "         [[ 20.],\n",
       "          [ 15.],\n",
       "          [ 22.],\n",
       "          ...,\n",
       "          [154.],\n",
       "          [133.],\n",
       "          [113.]]],\n",
       " \n",
       " \n",
       "        [[[ 30.],\n",
       "          [ 28.],\n",
       "          [ 28.],\n",
       "          ...,\n",
       "          [ 60.],\n",
       "          [ 50.],\n",
       "          [ 44.]],\n",
       " \n",
       "         [[ 30.],\n",
       "          [ 27.],\n",
       "          [ 28.],\n",
       "          ...,\n",
       "          [ 64.],\n",
       "          [ 52.],\n",
       "          [ 40.]],\n",
       " \n",
       "         [[ 31.],\n",
       "          [ 28.],\n",
       "          [ 30.],\n",
       "          ...,\n",
       "          [ 61.],\n",
       "          [ 54.],\n",
       "          [ 37.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[104.],\n",
       "          [109.],\n",
       "          [110.],\n",
       "          ...,\n",
       "          [ 35.],\n",
       "          [ 30.],\n",
       "          [ 30.]],\n",
       " \n",
       "         [[102.],\n",
       "          [105.],\n",
       "          [108.],\n",
       "          ...,\n",
       "          [ 35.],\n",
       "          [ 31.],\n",
       "          [ 29.]],\n",
       " \n",
       "         [[ 93.],\n",
       "          [ 96.],\n",
       "          [100.],\n",
       "          ...,\n",
       "          [ 35.],\n",
       "          [ 30.],\n",
       "          [ 28.]]],\n",
       " \n",
       " \n",
       "        [[[ 19.],\n",
       "          [ 13.],\n",
       "          [ 14.],\n",
       "          ...,\n",
       "          [108.],\n",
       "          [ 95.],\n",
       "          [ 86.]],\n",
       " \n",
       "         [[ 16.],\n",
       "          [ 17.],\n",
       "          [ 15.],\n",
       "          ...,\n",
       "          [105.],\n",
       "          [ 94.],\n",
       "          [ 90.]],\n",
       " \n",
       "         [[ 10.],\n",
       "          [  9.],\n",
       "          [ 10.],\n",
       "          ...,\n",
       "          [101.],\n",
       "          [ 93.],\n",
       "          [ 95.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 18.],\n",
       "          [ 14.],\n",
       "          [ 16.],\n",
       "          ...,\n",
       "          [ 55.],\n",
       "          [ 64.],\n",
       "          [ 95.]],\n",
       " \n",
       "         [[ 15.],\n",
       "          [ 15.],\n",
       "          [ 13.],\n",
       "          ...,\n",
       "          [123.],\n",
       "          [171.],\n",
       "          [192.]],\n",
       " \n",
       "         [[ 16.],\n",
       "          [ 14.],\n",
       "          [ 13.],\n",
       "          ...,\n",
       "          [189.],\n",
       "          [199.],\n",
       "          [201.]]]], dtype=float32), array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0]], dtype=uint8))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces, emotions = load_fer2013()\n",
    "faces, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = preprocess_input(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35887, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples, num_classes = emotions.shape\n",
    "num_samples, num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model\n",
    "Splited the data into 80% as training data and 20% as testing data.\n",
    "Trained the model by 35 number of epochs. Used xtest data as validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rosha\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/35\n",
      "898/897 [==============================] - 759s 845ms/step - loss: 1.7620 - acc: 0.3348 - val_loss: 1.7058 - val_acc: 0.4198\n",
      "Epoch 2/35\n",
      "898/897 [==============================] - 730s 813ms/step - loss: 1.5030 - acc: 0.4337 - val_loss: 1.6158 - val_acc: 0.4100\n",
      "Epoch 3/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.3918 - acc: 0.4762 - val_loss: 1.3649 - val_acc: 0.4928\n",
      "Epoch 4/35\n",
      "898/897 [==============================] - 730s 813ms/step - loss: 1.3181 - acc: 0.5068 - val_loss: 1.3208 - val_acc: 0.4974\n",
      "Epoch 5/35\n",
      "898/897 [==============================] - 730s 813ms/step - loss: 1.2741 - acc: 0.5232 - val_loss: 1.2893 - val_acc: 0.5171\n",
      "Epoch 6/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.2433 - acc: 0.5357 - val_loss: 1.3610 - val_acc: 0.4950\n",
      "Epoch 7/35\n",
      "898/897 [==============================] - 730s 813ms/step - loss: 1.2144 - acc: 0.5405 - val_loss: 1.1786 - val_acc: 0.5665\n",
      "Epoch 8/35\n",
      "898/897 [==============================] - 731s 814ms/step - loss: 1.1844 - acc: 0.5573 - val_loss: 1.1845 - val_acc: 0.5699\n",
      "Epoch 9/35\n",
      "898/897 [==============================] - 731s 814ms/step - loss: 1.1657 - acc: 0.5615 - val_loss: 1.1728 - val_acc: 0.5610\n",
      "Epoch 10/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.1515 - acc: 0.5682 - val_loss: 1.1915 - val_acc: 0.5619\n",
      "Epoch 11/35\n",
      "898/897 [==============================] - 730s 813ms/step - loss: 1.1350 - acc: 0.5759 - val_loss: 1.2300 - val_acc: 0.5493\n",
      "Epoch 12/35\n",
      "898/897 [==============================] - 731s 814ms/step - loss: 1.1276 - acc: 0.5737 - val_loss: 1.1354 - val_acc: 0.5715\n",
      "Epoch 13/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.1153 - acc: 0.5816 - val_loss: 1.1654 - val_acc: 0.5699\n",
      "Epoch 14/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.1049 - acc: 0.5862 - val_loss: 1.1572 - val_acc: 0.5861\n",
      "Epoch 15/35\n",
      "898/897 [==============================] - 731s 814ms/step - loss: 1.0943 - acc: 0.5877 - val_loss: 1.1551 - val_acc: 0.5745\n",
      "Epoch 16/35\n",
      "898/897 [==============================] - 731s 815ms/step - loss: 1.0810 - acc: 0.5928 - val_loss: 1.1195 - val_acc: 0.5933\n",
      "Epoch 17/35\n",
      "898/897 [==============================] - 733s 817ms/step - loss: 1.0754 - acc: 0.5976 - val_loss: 1.1067 - val_acc: 0.5914\n",
      "Epoch 18/35\n",
      "898/897 [==============================] - 734s 817ms/step - loss: 1.0677 - acc: 0.5971 - val_loss: 1.0827 - val_acc: 0.6000\n",
      "Epoch 19/35\n",
      "898/897 [==============================] - 734s 817ms/step - loss: 1.0621 - acc: 0.6020 - val_loss: 1.0697 - val_acc: 0.6066\n",
      "Epoch 20/35\n",
      "898/897 [==============================] - 742s 826ms/step - loss: 1.0563 - acc: 0.6060 - val_loss: 1.1106 - val_acc: 0.5906\n",
      "Epoch 21/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.0530 - acc: 0.6040 - val_loss: 1.0672 - val_acc: 0.6032\n",
      "Epoch 22/35\n",
      "898/897 [==============================] - 731s 815ms/step - loss: 1.0443 - acc: 0.6094 - val_loss: 1.1238 - val_acc: 0.5865\n",
      "Epoch 23/35\n",
      "898/897 [==============================] - 731s 814ms/step - loss: 1.0375 - acc: 0.6114 - val_loss: 1.0879 - val_acc: 0.6002\n",
      "Epoch 24/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.0295 - acc: 0.6170 - val_loss: 1.0691 - val_acc: 0.6052\n",
      "Epoch 25/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.0261 - acc: 0.6148 - val_loss: 1.1269 - val_acc: 0.5946\n",
      "Epoch 26/35\n",
      "898/897 [==============================] - 731s 814ms/step - loss: 1.0256 - acc: 0.6148 - val_loss: 1.1123 - val_acc: 0.5970\n",
      "Epoch 27/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.0204 - acc: 0.6173 - val_loss: 1.1333 - val_acc: 0.5750\n",
      "Epoch 28/35\n",
      "898/897 [==============================] - 731s 814ms/step - loss: 1.0131 - acc: 0.6211 - val_loss: 1.1156 - val_acc: 0.6004\n",
      "Epoch 29/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 1.0058 - acc: 0.6248 - val_loss: 1.1046 - val_acc: 0.5897\n",
      "Epoch 30/35\n",
      "898/897 [==============================] - 731s 815ms/step - loss: 1.0110 - acc: 0.6230 - val_loss: 1.1054 - val_acc: 0.5996\n",
      "Epoch 31/35\n",
      "898/897 [==============================] - 730s 813ms/step - loss: 0.9985 - acc: 0.6289 - val_loss: 1.0338 - val_acc: 0.6204\n",
      "Epoch 32/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 0.9978 - acc: 0.6260 - val_loss: 1.0474 - val_acc: 0.6106\n",
      "Epoch 33/35\n",
      "898/897 [==============================] - 732s 815ms/step - loss: 0.9910 - acc: 0.6312 - val_loss: 1.0498 - val_acc: 0.6190\n",
      "Epoch 34/35\n",
      "898/897 [==============================] - 731s 815ms/step - loss: 0.9896 - acc: 0.6291 - val_loss: 1.0605 - val_acc: 0.6089\n",
      "Epoch 35/35\n",
      "898/897 [==============================] - 733s 816ms/step - loss: 0.9897 - acc: 0.6281 - val_loss: 1.0230 - val_acc: 0.6258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f313f20208>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1,\n",
    "                        validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 48, 48, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28709, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "import imutils\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametersfor loading data and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for loading data and images\n",
    "detection_model_path = 'haarcascade_frontalface_default.xml'\n",
    "emotion_model_path = '_mini_XCEPTION.102-0.66.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading models\n",
    "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
    " \"neutral\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the data using Computer vision\n",
    "The dataset was tested on real time images by using computer vision. \n",
    "Based on the probabilities, each emotion is classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting video streaming\n",
    "cv2.namedWindow('Emotion_Recognition')\n",
    "camera = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    frame = camera.read()[1]\n",
    "    #reading the frame\n",
    "    frame = imutils.resize(frame,width=700)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    \n",
    "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
    "    frameClone = frame.copy()\n",
    "    if len(faces) > 0:\n",
    "        faces = sorted(faces, reverse=True,\n",
    "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
    "        (fX, fY, fW, fH) = faces\n",
    "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 28x28 pixels, and then prepare\n",
    "            # the ROI for classification via the CNN\n",
    "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
    "        roi = cv2.resize(roi, (64, 64))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        \n",
    "        \n",
    "        preds = emotion_classifier.predict(roi)[0]\n",
    "        emotion_probability = np.max(preds)\n",
    "        label = EMOTIONS[preds.argmax()]\n",
    "\n",
    " \n",
    "        for (i, (emotion, prob)) in enumerate(zip(EMOTIONS,preds)):\n",
    "                # construct the label text\n",
    "            text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
    "\n",
    "                # draw the label + probability bar on the canvas\n",
    "               # emoji_face = feelings_faces[np.argmax(preds)]\n",
    "\n",
    "                \n",
    "            w = int(prob * 300)\n",
    "            cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
    "            (w, (i * 35) + 35), (0, 0, 255), -1)\n",
    "            cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
    "            (255, 255, 255), 2)\n",
    "            cv2.putText(frameClone, label, (fX, fY - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "            cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
    "                              (0, 0, 255), 2)\n",
    "#    for c in range(0, 3):\n",
    "#        frame[200:320, 10:130, c] = emoji_face[:, :, c] * \\\n",
    "#        (emoji_face[:, :, 3] / 255.0) + frame[200:320,\n",
    "#        10:130, c] * (1.0 - emoji_face[:, :, 3] / 255.0)\n",
    "\n",
    "\n",
    "        cv2.imshow('your_face', frameClone)\n",
    "        cv2.imshow(\"Probabilities\", canvas)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description and Conclusion\n",
    "# CNN\n",
    "The main advantage of CNN compared to its predecessors is that it automatically detects the important features without any human supervision.\n",
    "CNN is also computationally efficient. It uses special convolution and pooling operations and performs parameter sharing.\n",
    "Convolution\n",
    "The main building block of CNN is the convolutional layer. Convolution is a mathematical operation to merge two sets of information. In our case the convolution is applied on the input data using a convolution filter to produce a feature map\n",
    "\n",
    "On the left side is the input to the convolution layer, for example the input image. On the right is the convolution filter, also called the kernel, we will use these terms interchangeably. This is called a 3x3 convolution due to the shape of the filter.\n",
    "We perform multiple convolutions on an input, each using a different filter and resulting in a distinct feature map. \n",
    "For any kind of neural network to be powerful, it needs to contain non-linearity.\n",
    "We again pass the result of the convolution operation through relu activation function. So the values in the final feature maps are not actually the sums, but the relu function applied to them.\n",
    "Stride specifies how much we move the convolution filter at each step. By default the value is 1.\n",
    "\n",
    "# Pooling\n",
    "After a convolution operation we usually perform pooling to reduce the dimensionality.\n",
    "type of pooling is max pooling which just takes the max value in the pooling window.\n",
    "Average pooling which just takes the avg of all the values in the pooling window.\n",
    "Then we flatten the output of the final pooling layer to a vector and that becomes the input to the fully connected layer.\n",
    " \n",
    "# Fully Connected Layer(FC)\n",
    "Fully connected layer involves weights, biases, and neurons. It connects neurons in one layer to neurons in another layer. It is used to classify images between different category by training.\n",
    "\n",
    "# Softmax / Logistic Layer\n",
    "Softmax or Logistic layer is the last layer of CNN. It resides at the end of FC layer. Logistic is used for binary classification and softmax is for multi-classification.(gives 7 outputs in our case)\n",
    "\n",
    "# Output Layer\n",
    "Output layer contains the label which is in the form of one-hot encoded.\n",
    "\n",
    "# Accuracy\n",
    "The model accuracy is 63% and its highest when compared with Random Forest and Nearest Neighbor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
